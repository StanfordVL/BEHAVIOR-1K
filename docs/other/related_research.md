# :material-book-plus: **Related Research**

### :fontawesome-solid-robot: [MoMaGen](https://momagen-rss.github.io/)

MoMaGen automatically generates diverse training datasets for bimanual mobile manipulation by solving constrained optimization problems that ensure robot reachability and camera visibility from minimal human demonstrations.

<iframe width="100%" height="281" style="max-width: 500px; border-radius: 8px; margin: 1rem 0;"
        src="https://player.vimeo.com/video/1102003564?autoplay=1&loop=1&autopause=0&muted=1&controls=0&title=0&byline=0&portrait=0&badge=0"
        frameborder="0" allowfullscreen>
</iframe>

### :material-robot-industrial: [BEHAVIOR Robot Suite](https://behavior-robot-suite.github.io/)

BEHAVIOR Robot Suite (BRS) provides the robot embodiment needed for complex household tasks. Built on a bimanual wheeled robot with a 4-DoF torso, BRS integrates a cost-effective teleoperation interface for data collection and a novel algorithm for learning whole-body visuomotor policies.

<iframe width="100%" height="281" style="max-width: 500px; border-radius: 8px; margin: 1rem 0;"
        src="https://player.vimeo.com/video/1101969680?autoplay=1&loop=1&autopause=0&muted=1&controls=0&title=0&byline=0&portrait=0&badge=0"
        frameborder="0" allowfullscreen>
</iframe>

### :fontawesome-solid-couch: [Automated Creation of Digital Cousins for Robust Policy Learning](https://digital-cousins.github.io/)

ACDC (Automatic Creation of Digital Cousins) is a method that addresses the limitations of real-world robot training and sim-to-real transfer by introducing "digital cousins" - virtual environments that capture similar geometric and semantic affordances to real scenes without explicitly modeling them.

<iframe width="100%" height="281" style="max-width: 500px; border-radius: 8px; margin: 1rem 0;"
        src="https://player.vimeo.com/video/1101969699?autoplay=1&loop=1&autopause=0&muted=1&controls=0&title=0&byline=0&portrait=0&badge=0"
        frameborder="0" allowfullscreen>
</iframe>

### :material-glasses: [BEHAVIOR Vision Suite](https://behavior-vision-suite.github.io/)

BEHAVIOR Vision Suite is a synthetic data generator that addresses limitations in current computer vision datasets by providing high-quality, controllable data generation. It offers adjustable parameters at scene, object, and camera levels, enabling researchers to conduct controlled experiments.

<iframe width="100%" height="281" style="max-width: 500px; border-radius: 8px; margin: 1rem 0;"
        src="https://player.vimeo.com/video/1101969653?autoplay=1&loop=1&autopause=0&muted=1&controls=0&title=0&byline=0&portrait=0&badge=0"
        frameborder="0" allowfullscreen>
</iframe>

## :material-desk-lamp: BEHAVIOR Series

### [BEHAVIOR-100](../behavior_100/overview.md)

BEHAVIOR-100 is the first generation of BEHAVIOR, a benchmark for embodied AI with 100 activities instantiated in iGibson 2.0.

### [BEHAVIOR-1K](../index.md)

BEHAVIOR-1K is the latest generation of BEHAVIOR, featuring 1000 household tasks that significantly expand beyond BEHAVIOR-100 in both quantity and diversity, instantiated in OmniGibson with full-length, realistic task complexity.

## :fontawesome-solid-house: Gibson Simulation Series

The Gibson series is named after James J. Gibson, the author of Ecological Approach to Visual Perception, 1979. Read a relevant excerpt of JJ Gibson's book [here](http://gibsonenv.stanford.edu/The_Ecological_Approach_to_Visual_Perception_by_JJ_Gibson.pdf). “We must perceive in order to move, but we must also move in order to perceive” – JJ Gibson.

### [Gibson](http://gibsonenv.stanford.edu/)

Virtualized real-world spaces, featuring 1400+ floor spaces from 572 real buildings

### [iGibson 1.0](https://svl.stanford.edu/igibson/)

Added full scene interactivity with rigid & articulated objects, domain randomization, and human demonstration collection across 15 home environments

### [iGibson 2.0](https://svl.stanford.edu/igibson/)

Introduced object states (temperature, wetness, cleanliness), predicate logic for task reasoning, and VR-based human demonstrations for complex multi-step activities

### [OmniGibson](../omnigibson/overview.md)

Advanced physics for rigid bodies, deformables, and liquids across 50+ diverse scenes (homes, offices, restaurants) with 10,000+ richly annotated objects

